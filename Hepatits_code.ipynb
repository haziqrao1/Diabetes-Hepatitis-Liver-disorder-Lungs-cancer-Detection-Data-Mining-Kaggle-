{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.792208</td>\n",
       "      <td>41.272727</td>\n",
       "      <td>1.097403</td>\n",
       "      <td>1.844156</td>\n",
       "      <td>1.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.407051</td>\n",
       "      <td>12.574106</td>\n",
       "      <td>0.297473</td>\n",
       "      <td>0.363891</td>\n",
       "      <td>0.499554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class         AGE         SEX  ANTIVIRALS   HISTOLOGY\n",
       "count  154.000000  154.000000  154.000000  154.000000  154.000000\n",
       "mean     1.792208   41.272727    1.097403    1.844156    1.454545\n",
       "std      0.407051   12.574106    0.297473    0.363891    0.499554\n",
       "min      1.000000    7.000000    1.000000    1.000000    1.000000\n",
       "25%      2.000000   32.000000    1.000000    2.000000    1.000000\n",
       "50%      2.000000   39.000000    1.000000    2.000000    1.000000\n",
       "75%      2.000000   50.000000    1.000000    2.000000    2.000000\n",
       "max      2.000000   78.000000    2.000000    2.000000    2.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"hepatitis-data.txt\")\n",
    "data.columns=['Class','AGE'\n",
    "      ,'SEX'\n",
    "      ,'STEROID'\n",
    "      ,'ANTIVIRALS'\n",
    "      ,'FATIGUE'\n",
    "      ,'MALAISE'\n",
    "     , 'ANOREXIA'\n",
    "     , 'LIVER BIG'\n",
    "     ,'LIVER FIRM'\n",
    "     ,'SPLEEN PALPABLE'\n",
    "     ,'SPIDERS'\n",
    "     ,'ASCITES'\n",
    "     ,'VARICES'\n",
    "     ,'BILIRUBIN'\n",
    "     ,'ALK PHOSPHATE'\n",
    "     ,'SGOT'\n",
    "     ,'ALBUMIN'\n",
    "     ,'PROTIME'\n",
    "     ,'HISTOLOGY']\n",
    "df2=data\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>STEROID</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>MALAISE</th>\n",
       "      <th>ANOREXIA</th>\n",
       "      <th>LIVER BIG</th>\n",
       "      <th>LIVER FIRM</th>\n",
       "      <th>SPLEEN PALPABLE</th>\n",
       "      <th>SPIDERS</th>\n",
       "      <th>ASCITES</th>\n",
       "      <th>VARICES</th>\n",
       "      <th>BILIRUBIN</th>\n",
       "      <th>ALK PHOSPHATE</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>ALBUMIN</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>135</td>\n",
       "      <td>42</td>\n",
       "      <td>3.5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>?</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>95</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.60</td>\n",
       "      <td>?</td>\n",
       "      <td>242</td>\n",
       "      <td>3.3</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>126</td>\n",
       "      <td>142</td>\n",
       "      <td>4.3</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>4.1</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>4.1</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.20</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>3.1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  AGE  SEX STEROID  ANTIVIRALS FATIGUE MALAISE ANOREXIA LIVER BIG  \\\n",
       "0        2   50    1       1           2       1       2        2         1   \n",
       "1        2   78    1       2           2       1       2        2         2   \n",
       "2        2   31    1       ?           1       2       2        2         2   \n",
       "3        2   34    1       2           2       2       2        2         2   \n",
       "4        2   34    1       2           2       2       2        2         2   \n",
       "..     ...  ...  ...     ...         ...     ...     ...      ...       ...   \n",
       "149      1   46    1       2           2       1       1        1         2   \n",
       "150      2   44    1       2           2       1       2        2         2   \n",
       "151      2   61    1       1           2       1       1        2         1   \n",
       "152      2   53    2       1           2       1       2        2         2   \n",
       "153      1   43    1       2           2       1       2        2         2   \n",
       "\n",
       "    LIVER FIRM SPLEEN PALPABLE SPIDERS ASCITES VARICES BILIRUBIN  \\\n",
       "0            2               2       2       2       2      0.90   \n",
       "1            2               2       2       2       2      0.70   \n",
       "2            2               2       2       2       2      0.70   \n",
       "3            2               2       2       2       2      1.00   \n",
       "4            2               2       2       2       2      0.90   \n",
       "..         ...             ...     ...     ...     ...       ...   \n",
       "149          2               2       1       1       1      7.60   \n",
       "150          1               2       2       2       2      0.90   \n",
       "151          1               2       1       2       2      0.80   \n",
       "152          2               1       1       2       1      1.50   \n",
       "153          2               1       1       1       2      1.20   \n",
       "\n",
       "    ALK PHOSPHATE SGOT ALBUMIN PROTIME  HISTOLOGY  \n",
       "0             135   42     3.5       ?          1  \n",
       "1              96   32     4.0       ?          1  \n",
       "2              46   52     4.0      80          1  \n",
       "3               ?  200     4.0       ?          1  \n",
       "4              95   28     4.0      75          1  \n",
       "..            ...  ...     ...     ...        ...  \n",
       "149             ?  242     3.3      50          2  \n",
       "150           126  142     4.3       ?          2  \n",
       "151            75   20     4.1       ?          2  \n",
       "152            81   19     4.1      48          2  \n",
       "153           100   19     3.1      42          2  \n",
       "\n",
       "[154 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=data\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing ? to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['STEROID'] = df2['STEROID'].str.replace('?', '')\n",
    "df2['FATIGUE'] = df2['FATIGUE'].str.replace('?', '')\n",
    "df2['MALAISE'] = df2['MALAISE'].str.replace('?', '')\n",
    "df2['ANOREXIA'] = df2['ANOREXIA'].str.replace('?', '')\n",
    "df2['LIVER BIG'] = df2['LIVER BIG'].str.replace('?', '')\n",
    "df2['LIVER FIRM'] = df2['LIVER FIRM'].str.replace('?', '')\n",
    "df2['SPLEEN PALPABLE'] = df2['SPLEEN PALPABLE'].str.replace('?', '')\n",
    "df2['SPIDERS'] = df2['SPIDERS'].str.replace('?', '')\n",
    "df2['ASCITES'] = df2['ASCITES'].str.replace('?', '')\n",
    "df2['VARICES'] = df2['VARICES'].str.replace('?', '')\n",
    "df2['BILIRUBIN'] = df2['BILIRUBIN'].str.replace('?', '')\n",
    "df2['ALK PHOSPHATE'] = df2['ALK PHOSPHATE'].str.replace('?', '')\n",
    "df2['SGOT'] = df2['SGOT'].str.replace('?', '')\n",
    "df2['ALBUMIN'] = df2['ALBUMIN'].str.replace('?', '')\n",
    "df2['PROTIME'] = df2['PROTIME'].str.replace('?', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['STEROID'] = df2['STEROID'].fillna(df2['STEROID'].median())\n",
    "df2['FATIGUE'] = df2['FATIGUE'].fillna(df2['FATIGUE'].median())\n",
    "df2['MALAISE'] = df2['MALAISE'].fillna(df2['MALAISE'].median())\n",
    "df2['ANOREXIA'] = df2['ANOREXIA'].fillna(df2['ANOREXIA'].median())\n",
    "df2['LIVER BIG'] = df2['LIVER BIG'].fillna(df2['LIVER BIG'].median())\n",
    "df2['LIVER FIRM'] = df2['LIVER FIRM'].fillna(df2['LIVER FIRM'].median())\n",
    "df2['SPLEEN PALPABLE'] = df2['SPLEEN PALPABLE'].fillna(df2['SPLEEN PALPABLE'].median())\n",
    "df2['SPIDERS'] = df2['SPIDERS'].fillna(df2['SPIDERS'].median())\n",
    "df2['ASCITES'] = df2['ASCITES'].fillna(df2['ASCITES'].median())\n",
    "df2['VARICES'] = df2['VARICES'].fillna(df2['VARICES'].median())\n",
    "df2['BILIRUBIN'] = df2['BILIRUBIN'].fillna(df2['BILIRUBIN'].median())\n",
    "df2['ALK PHOSPHATE'] = df2['ALK PHOSPHATE'].fillna(df2['ALK PHOSPHATE'].median())\n",
    "df2['SGOT'] = df2['SGOT'].fillna(df2['SGOT'].median())\n",
    "df2['ALBUMIN'] = df2['ALBUMIN'].fillna(df2['ALBUMIN'].median())\n",
    "df2['PROTIME'] = df2['PROTIME'].fillna(df2['PROTIME'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN implementation\n",
    "from collections import Counter\n",
    "def euclidian_distance(a,b):\n",
    "    half=np.sum(a-b)**2\n",
    "    return (np.sqrt(half))\n",
    "\n",
    "class KNN():\n",
    "\n",
    "    X_train=0\n",
    "    Y_train=0\n",
    "    test_size=45\n",
    "    k=0\n",
    "    def __init__(self, k, scalefeatures=False):        \n",
    "        self.k=k\n",
    "    def fit(self,x,y):\n",
    "        self.X_train=x\n",
    "        self.Y_train=y\n",
    "        \n",
    "    \n",
    "    def Compute_distances(self,X):\n",
    "        dists=[euclidian_distance(X,x1) for x1 in self.X_train]\n",
    "        dists2= np.argsort(dists)[:self.k]\n",
    "        dist3=[self.Y_train[i] for i in dists2]\n",
    "        dist4= Counter(dist3).most_common(1)\n",
    "        return dist4[0][0]\n",
    "    \n",
    "    def predict(self,X):\n",
    "        pclass = [self.Compute_distances(x) for x in X ]\n",
    "        return np.array(pclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-55a8f712bea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Build a 3-nearest neighbour classifier...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "# Build a 3-nearest neighbour classifier...\n",
    "c1=KNN(13)\n",
    "c1.fit(Xtrain,Ytrain)\n",
    "predictions = c1.predict(Xtest)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-57a836fe868f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Check the accuracy on the test set..\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "#Check the accuracy on the test set..\n",
    "accuracy = np.sum(predictions == Ytest)/len(Ytest)\n",
    "accuracy=accuracy*100\n",
    "print(accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>STEROID</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>MALAISE</th>\n",
       "      <th>ANOREXIA</th>\n",
       "      <th>LIVER BIG</th>\n",
       "      <th>LIVER FIRM</th>\n",
       "      <th>SPLEEN PALPABLE</th>\n",
       "      <th>SPIDERS</th>\n",
       "      <th>ASCITES</th>\n",
       "      <th>VARICES</th>\n",
       "      <th>BILIRUBIN</th>\n",
       "      <th>ALK PHOSPHATE</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>ALBUMIN</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.792208</td>\n",
       "      <td>41.272727</td>\n",
       "      <td>1.097403</td>\n",
       "      <td>1.512987</td>\n",
       "      <td>1.844156</td>\n",
       "      <td>1.344156</td>\n",
       "      <td>1.603896</td>\n",
       "      <td>1.792208</td>\n",
       "      <td>1.844156</td>\n",
       "      <td>1.610390</td>\n",
       "      <td>1.805195</td>\n",
       "      <td>1.668831</td>\n",
       "      <td>1.870130</td>\n",
       "      <td>1.883117</td>\n",
       "      <td>1.413636</td>\n",
       "      <td>101.62987</td>\n",
       "      <td>85.610390</td>\n",
       "      <td>3.835065</td>\n",
       "      <td>61.487013</td>\n",
       "      <td>1.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.407051</td>\n",
       "      <td>12.574106</td>\n",
       "      <td>0.297473</td>\n",
       "      <td>0.501462</td>\n",
       "      <td>0.363891</td>\n",
       "      <td>0.476642</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.363891</td>\n",
       "      <td>0.489253</td>\n",
       "      <td>0.397343</td>\n",
       "      <td>0.472169</td>\n",
       "      <td>0.337257</td>\n",
       "      <td>0.322329</td>\n",
       "      <td>1.194599</td>\n",
       "      <td>47.21664</td>\n",
       "      <td>88.712012</td>\n",
       "      <td>0.621145</td>\n",
       "      <td>17.254813</td>\n",
       "      <td>0.499554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>119.75000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>295.00000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class         AGE         SEX     STEROID  ANTIVIRALS     FATIGUE  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000  154.000000  154.000000   \n",
       "mean     1.792208   41.272727    1.097403    1.512987    1.844156    1.344156   \n",
       "std      0.407051   12.574106    0.297473    0.501462    0.363891    0.476642   \n",
       "min      1.000000    7.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000   32.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      2.000000   39.000000    1.000000    2.000000    2.000000    1.000000   \n",
       "75%      2.000000   50.000000    1.000000    2.000000    2.000000    2.000000   \n",
       "max      2.000000   78.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "\n",
       "          MALAISE    ANOREXIA   LIVER BIG  LIVER FIRM  SPLEEN PALPABLE  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000       154.000000   \n",
       "mean     1.603896    1.792208    1.844156    1.610390         1.805195   \n",
       "std      0.490682    0.407051    0.363891    0.489253         0.397343   \n",
       "min      1.000000    1.000000    1.000000    1.000000         1.000000   \n",
       "25%      1.000000    2.000000    2.000000    1.000000         2.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
       "75%      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
       "max      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
       "\n",
       "          SPIDERS     ASCITES     VARICES   BILIRUBIN  ALK PHOSPHATE  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000      154.00000   \n",
       "mean     1.668831    1.870130    1.883117    1.413636      101.62987   \n",
       "std      0.472169    0.337257    0.322329    1.194599       47.21664   \n",
       "min      1.000000    1.000000    1.000000    0.300000       26.00000   \n",
       "25%      1.000000    2.000000    2.000000    0.800000       78.00000   \n",
       "50%      2.000000    2.000000    2.000000    1.000000       85.00000   \n",
       "75%      2.000000    2.000000    2.000000    1.500000      119.75000   \n",
       "max      2.000000    2.000000    2.000000    8.000000      295.00000   \n",
       "\n",
       "             SGOT     ALBUMIN     PROTIME   HISTOLOGY  \n",
       "count  154.000000  154.000000  154.000000  154.000000  \n",
       "mean    85.610390    3.835065   61.487013    1.454545  \n",
       "std     88.712012    0.621145   17.254813    0.499554  \n",
       "min     14.000000    2.100000    0.000000    1.000000  \n",
       "25%     33.000000    3.500000   57.000000    1.000000  \n",
       "50%     58.000000    4.000000   61.000000    1.000000  \n",
       "75%     99.500000    4.200000   65.500000    2.000000  \n",
       "max    648.000000    6.400000  100.000000    2.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Giving values to X and Y \n",
    "Y=df2.iloc[:, 0].values\n",
    "X=df2.iloc[ : , df2.columns != 'Class'].values\n",
    "df2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class              0\n",
       "AGE                0\n",
       "SEX                0\n",
       "STEROID            0\n",
       "ANTIVIRALS         0\n",
       "FATIGUE            0\n",
       "MALAISE            0\n",
       "ANOREXIA           0\n",
       "LIVER BIG          0\n",
       "LIVER FIRM         0\n",
       "SPLEEN PALPABLE    0\n",
       "SPIDERS            0\n",
       "ASCITES            0\n",
       "VARICES            0\n",
       "BILIRUBIN          0\n",
       "ALK PHOSPHATE      0\n",
       "SGOT               0\n",
       "ALBUMIN            0\n",
       "PROTIME            0\n",
       "HISTOLOGY          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>STEROID</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>MALAISE</th>\n",
       "      <th>ANOREXIA</th>\n",
       "      <th>LIVER BIG</th>\n",
       "      <th>LIVER FIRM</th>\n",
       "      <th>SPLEEN PALPABLE</th>\n",
       "      <th>SPIDERS</th>\n",
       "      <th>ASCITES</th>\n",
       "      <th>VARICES</th>\n",
       "      <th>BILIRUBIN</th>\n",
       "      <th>ALK PHOSPHATE</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>ALBUMIN</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.792208</td>\n",
       "      <td>41.272727</td>\n",
       "      <td>1.097403</td>\n",
       "      <td>1.512987</td>\n",
       "      <td>1.844156</td>\n",
       "      <td>1.344156</td>\n",
       "      <td>1.603896</td>\n",
       "      <td>1.792208</td>\n",
       "      <td>1.844156</td>\n",
       "      <td>1.610390</td>\n",
       "      <td>1.805195</td>\n",
       "      <td>1.668831</td>\n",
       "      <td>1.870130</td>\n",
       "      <td>1.883117</td>\n",
       "      <td>1.413636</td>\n",
       "      <td>101.62987</td>\n",
       "      <td>85.610390</td>\n",
       "      <td>3.835065</td>\n",
       "      <td>61.487013</td>\n",
       "      <td>1.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.407051</td>\n",
       "      <td>12.574106</td>\n",
       "      <td>0.297473</td>\n",
       "      <td>0.501462</td>\n",
       "      <td>0.363891</td>\n",
       "      <td>0.476642</td>\n",
       "      <td>0.490682</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.363891</td>\n",
       "      <td>0.489253</td>\n",
       "      <td>0.397343</td>\n",
       "      <td>0.472169</td>\n",
       "      <td>0.337257</td>\n",
       "      <td>0.322329</td>\n",
       "      <td>1.194599</td>\n",
       "      <td>47.21664</td>\n",
       "      <td>88.712012</td>\n",
       "      <td>0.621145</td>\n",
       "      <td>17.254813</td>\n",
       "      <td>0.499554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>119.75000</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>295.00000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class         AGE         SEX     STEROID  ANTIVIRALS     FATIGUE  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000  154.000000  154.000000   \n",
       "mean     1.792208   41.272727    1.097403    1.512987    1.844156    1.344156   \n",
       "std      0.407051   12.574106    0.297473    0.501462    0.363891    0.476642   \n",
       "min      1.000000    7.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      2.000000   32.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      2.000000   39.000000    1.000000    2.000000    2.000000    1.000000   \n",
       "75%      2.000000   50.000000    1.000000    2.000000    2.000000    2.000000   \n",
       "max      2.000000   78.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "\n",
       "          MALAISE    ANOREXIA   LIVER BIG  LIVER FIRM  SPLEEN PALPABLE  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000       154.000000   \n",
       "mean     1.603896    1.792208    1.844156    1.610390         1.805195   \n",
       "std      0.490682    0.407051    0.363891    0.489253         0.397343   \n",
       "min      1.000000    1.000000    1.000000    1.000000         1.000000   \n",
       "25%      1.000000    2.000000    2.000000    1.000000         2.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
       "75%      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
       "max      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
       "\n",
       "          SPIDERS     ASCITES     VARICES   BILIRUBIN  ALK PHOSPHATE  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000      154.00000   \n",
       "mean     1.668831    1.870130    1.883117    1.413636      101.62987   \n",
       "std      0.472169    0.337257    0.322329    1.194599       47.21664   \n",
       "min      1.000000    1.000000    1.000000    0.300000       26.00000   \n",
       "25%      1.000000    2.000000    2.000000    0.800000       78.00000   \n",
       "50%      2.000000    2.000000    2.000000    1.000000       85.00000   \n",
       "75%      2.000000    2.000000    2.000000    1.500000      119.75000   \n",
       "max      2.000000    2.000000    2.000000    8.000000      295.00000   \n",
       "\n",
       "             SGOT     ALBUMIN     PROTIME   HISTOLOGY  \n",
       "count  154.000000  154.000000  154.000000  154.000000  \n",
       "mean    85.610390    3.835065   61.487013    1.454545  \n",
       "std     88.712012    0.621145   17.254813    0.499554  \n",
       "min     14.000000    2.100000    0.000000    1.000000  \n",
       "25%     33.000000    3.500000   57.000000    1.000000  \n",
       "50%     58.000000    4.000000   61.000000    1.000000  \n",
       "75%     99.500000    4.200000   65.500000    2.000000  \n",
       "max    648.000000    6.400000  100.000000    2.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of data\n",
    "#scaling is not required in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50.   1.   1.  ...  3.5 61.   1. ]\n",
      " [78.   1.   2.  ...  4.  61.   1. ]\n",
      " [31.   1.   2.  ...  4.  80.   1. ]\n",
      " ...\n",
      " [61.   1.   1.  ...  4.1 61.   2. ]\n",
      " [53.   2.   1.  ...  4.1 48.   2. ]\n",
      " [43.   1.   2.  ...  3.1 42.   2. ]]\n",
      "[2.771e+01 3.492e-01 5.083e-01 1.908e-01 2.384e+00 2.622e+00 2.471e-01\n",
      " 8.445e-02 6.945e-03 7.266e-01 3.073e+00 2.044e+00 1.104e+00 3.051e+01\n",
      " 5.167e+01 6.358e+01 3.194e+00 7.011e+01 2.964e+00]\n",
      "[[9.00e-01 1.35e+02 4.20e+01 6.10e+01]\n",
      " [7.00e-01 9.60e+01 3.20e+01 6.10e+01]\n",
      " [7.00e-01 4.60e+01 5.20e+01 8.00e+01]\n",
      " [1.00e+00 8.50e+01 2.00e+02 6.10e+01]\n",
      " [9.00e-01 9.50e+01 2.80e+01 7.50e+01]\n",
      " [1.00e+00 8.50e+01 5.80e+01 6.10e+01]\n",
      " [1.00e+00 8.50e+01 5.80e+01 6.10e+01]\n",
      " [7.00e-01 8.50e+01 4.80e+01 6.10e+01]\n",
      " [1.00e+00 8.50e+01 1.20e+02 6.10e+01]\n",
      " [1.30e+00 7.80e+01 3.00e+01 8.50e+01]\n",
      " [1.00e+00 5.90e+01 2.49e+02 5.40e+01]\n",
      " [9.00e-01 8.10e+01 6.00e+01 5.20e+01]\n",
      " [2.20e+00 5.70e+01 1.44e+02 7.80e+01]\n",
      " [1.00e+00 8.50e+01 6.00e+01 6.10e+01]\n",
      " [2.00e+00 7.20e+01 8.90e+01 4.60e+01]\n",
      " [1.20e+00 1.02e+02 5.30e+01 6.10e+01]\n",
      " [6.00e-01 6.20e+01 1.66e+02 6.30e+01]\n",
      " [7.00e-01 5.30e+01 4.20e+01 8.50e+01]\n",
      " [7.00e-01 7.00e+01 2.80e+01 6.20e+01]\n",
      " [9.00e-01 4.80e+01 2.00e+01 6.40e+01]\n",
      " [1.20e+00 1.33e+02 9.80e+01 3.90e+01]\n",
      " [1.00e+00 8.50e+01 2.00e+01 1.00e+02]\n",
      " [9.00e-01 6.00e+01 6.30e+01 4.70e+01]\n",
      " [4.00e-01 4.50e+01 1.80e+01 7.00e+01]\n",
      " [8.00e-01 9.50e+01 4.60e+01 1.00e+02]\n",
      " [6.00e-01 8.50e+01 4.80e+01 6.10e+01]\n",
      " [1.40e+00 1.75e+02 5.50e+01 3.60e+01]\n",
      " [1.30e+00 7.80e+01 2.50e+01 1.00e+02]\n",
      " [1.00e+00 7.80e+01 5.80e+01 5.20e+01]\n",
      " [2.30e+00 2.80e+02 9.80e+01 4.00e+01]\n",
      " [1.00e+00 8.50e+01 6.00e+01 6.10e+01]\n",
      " [7.00e-01 8.10e+01 5.30e+01 7.40e+01]\n",
      " [5.00e-01 1.35e+02 2.90e+01 6.00e+01]\n",
      " [9.00e-01 5.80e+01 9.20e+01 7.30e+01]\n",
      " [6.00e-01 6.70e+01 2.80e+01 6.10e+01]\n",
      " [1.30e+00 1.94e+02 1.50e+02 9.00e+01]\n",
      " [2.30e+00 1.50e+02 6.80e+01 6.10e+01]\n",
      " [1.00e+00 8.50e+01 1.40e+01 1.00e+02]\n",
      " [3.00e-01 1.80e+02 5.30e+01 7.40e+01]\n",
      " [7.00e-01 7.50e+01 5.50e+01 2.10e+01]\n",
      " [4.60e+00 5.60e+01 1.60e+01 6.10e+01]\n",
      " [1.00e+00 4.60e+01 9.00e+01 6.00e+01]\n",
      " [7.00e-01 7.10e+01 1.80e+01 1.00e+02]\n",
      " [1.00e+00 8.50e+01 8.60e+01 6.10e+01]\n",
      " [7.00e-01 7.40e+01 1.10e+02 6.10e+01]\n",
      " [6.00e-01 8.00e+01 8.00e+01 6.10e+01]\n",
      " [1.80e+00 1.91e+02 4.20e+02 4.60e+01]\n",
      " [8.00e-01 8.50e+01 4.40e+01 8.50e+01]\n",
      " [7.00e-01 1.25e+02 6.50e+01 7.70e+01]\n",
      " [9.00e-01 8.50e+01 6.00e+01 6.10e+01]\n",
      " [1.00e+00 8.50e+01 2.00e+01 6.10e+01]\n",
      " [6.00e-01 1.10e+02 1.45e+02 7.00e+01]\n",
      " [1.20e+00 8.50e+01 3.10e+01 1.00e+02]\n",
      " [7.00e-01 5.00e+01 7.80e+01 7.40e+01]\n",
      " [8.00e-01 9.20e+01 5.90e+01 6.10e+01]\n",
      " [1.00e+00 8.50e+01 5.80e+01 6.10e+01]\n",
      " [7.00e-01 5.20e+01 3.80e+01 5.20e+01]\n",
      " [1.00e+00 8.00e+01 3.80e+01 7.40e+01]\n",
      " [1.00e+00 8.50e+01 7.50e+01 6.10e+01]\n",
      " [7.00e-01 2.60e+01 5.80e+01 1.00e+02]\n",
      " [7.00e-01 1.02e+02 6.40e+01 9.00e+01]\n",
      " [3.50e+00 2.15e+02 5.40e+01 2.90e+01]\n",
      " [7.00e-01 1.64e+02 4.40e+01 4.10e+01]\n",
      " [8.00e-01 1.03e+02 4.30e+01 6.60e+01]\n",
      " [8.00e-01 8.50e+01 3.80e+01 6.10e+01]\n",
      " [7.00e-01 6.20e+01 3.30e+01 6.10e+01]\n",
      " [4.10e+00 8.50e+01 4.80e+01 7.30e+01]\n",
      " [1.00e+00 3.40e+01 1.50e+01 5.40e+01]\n",
      " [1.60e+00 6.80e+01 6.80e+01 6.10e+01]\n",
      " [8.00e-01 8.20e+01 3.90e+01 6.10e+01]\n",
      " [2.80e+00 1.27e+02 1.82e+02 6.10e+01]\n",
      " [9.00e-01 7.60e+01 2.71e+02 6.10e+01]\n",
      " [1.00e+00 8.50e+01 4.50e+01 5.70e+01]\n",
      " [1.50e+00 1.00e+02 1.00e+02 6.10e+01]\n",
      " [1.00e+00 5.50e+01 4.50e+01 5.60e+01]\n",
      " [2.00e+00 1.67e+02 2.42e+02 6.10e+01]\n",
      " [6.00e-01 3.00e+01 2.40e+01 7.60e+01]\n",
      " [1.00e+00 7.20e+01 4.60e+01 5.70e+01]\n",
      " [7.00e-01 8.50e+01 3.10e+01 6.10e+01]\n",
      " [8.00e-01 8.50e+01 1.40e+01 6.10e+01]\n",
      " [7.00e-01 6.20e+01 2.24e+02 1.00e+02]\n",
      " [7.00e-01 1.00e+02 3.10e+01 1.00e+02]\n",
      " [1.50e+00 1.79e+02 6.90e+01 6.10e+01]\n",
      " [1.30e+00 1.41e+02 1.56e+02 5.80e+01]\n",
      " [1.60e+00 4.40e+01 1.23e+02 4.60e+01]\n",
      " [9.00e-01 1.35e+02 5.50e+01 4.10e+01]\n",
      " [2.50e+00 1.65e+02 6.40e+01 6.10e+01]\n",
      " [1.20e+00 1.18e+02 1.60e+01 6.10e+01]\n",
      " [6.00e-01 7.60e+01 1.80e+01 8.40e+01]\n",
      " [9.00e-01 2.30e+02 1.17e+02 4.10e+01]\n",
      " [4.60e+00 8.50e+01 5.50e+01 6.10e+01]\n",
      " [1.00e+00 8.50e+01 6.00e+01 6.10e+01]\n",
      " [1.50e+00 8.50e+01 6.90e+01 6.10e+01]\n",
      " [1.50e+00 1.07e+02 1.57e+02 3.80e+01]\n",
      " [6.00e-01 4.00e+01 6.90e+01 6.70e+01]\n",
      " [8.00e-01 1.47e+02 1.28e+02 1.00e+02]\n",
      " [3.00e+00 1.14e+02 6.50e+01 6.10e+01]\n",
      " [2.00e+00 8.40e+01 2.30e+01 6.60e+01]\n",
      " [1.00e+00 8.50e+01 4.00e+01 6.10e+01]\n",
      " [4.80e+00 1.23e+02 1.57e+02 3.10e+01]\n",
      " [7.00e-01 8.50e+01 2.40e+01 6.10e+01]\n",
      " [2.40e+00 1.68e+02 2.27e+02 6.60e+01]\n",
      " [4.60e+00 2.15e+02 2.69e+02 5.10e+01]\n",
      " [1.70e+00 8.60e+01 2.00e+01 4.60e+01]\n",
      " [6.00e-01 8.50e+01 3.40e+01 6.10e+01]\n",
      " [1.50e+00 1.38e+02 5.80e+01 6.10e+01]\n",
      " [2.30e+00 8.50e+01 6.48e+02 6.10e+01]\n",
      " [1.00e+00 1.55e+02 2.25e+02 6.70e+01]\n",
      " [7.00e-01 6.30e+01 8.00e+01 3.10e+01]\n",
      " [7.00e-01 2.56e+02 2.50e+01 6.10e+01]\n",
      " [5.00e-01 6.20e+01 6.80e+01 2.90e+01]\n",
      " [1.00e+00 8.50e+01 3.00e+01 6.10e+01]\n",
      " [1.20e+00 8.10e+01 6.50e+01 6.10e+01]\n",
      " [1.10e+00 1.41e+02 7.50e+01 6.10e+01]\n",
      " [3.20e+00 1.19e+02 1.36e+02 6.10e+01]\n",
      " [1.00e+00 8.50e+01 3.40e+01 6.10e+01]\n",
      " [1.00e+00 1.39e+02 8.10e+01 6.20e+01]\n",
      " [1.00e+00 8.50e+01 5.80e+01 6.10e+01]\n",
      " [3.20e+00 8.50e+01 2.80e+01 6.10e+01]\n",
      " [2.90e+00 9.00e+01 1.53e+02 6.10e+01]\n",
      " [1.00e+00 1.60e+02 1.18e+02 2.30e+01]\n",
      " [1.50e+00 8.50e+01 4.00e+01 6.10e+01]\n",
      " [9.00e-01 8.50e+01 2.31e+02 6.10e+01]\n",
      " [1.00e+00 8.50e+01 7.50e+01 7.20e+01]\n",
      " [7.00e-01 7.00e+01 2.40e+01 1.00e+02]\n",
      " [1.00e+00 8.50e+01 2.00e+01 6.10e+01]\n",
      " [2.80e+00 1.55e+02 7.50e+01 3.20e+01]\n",
      " [1.20e+00 8.50e+01 9.20e+01 6.60e+01]\n",
      " [4.60e+00 8.20e+01 5.50e+01 3.00e+01]\n",
      " [1.00e+00 8.50e+01 3.00e+01 0.00e+00]\n",
      " [8.00e+00 8.50e+01 1.01e+02 6.10e+01]\n",
      " [2.00e+00 1.58e+02 2.78e+02 6.10e+01]\n",
      " [1.00e+00 1.15e+02 5.20e+01 5.00e+01]\n",
      " [4.00e-01 2.43e+02 4.90e+01 9.00e+01]\n",
      " [1.30e+00 1.81e+02 1.81e+02 5.70e+01]\n",
      " [8.00e-01 8.50e+01 3.30e+01 6.10e+01]\n",
      " [1.60e+00 1.30e+02 1.40e+02 5.60e+01]\n",
      " [1.00e+00 1.66e+02 3.00e+01 3.10e+01]\n",
      " [1.30e+00 8.50e+01 4.40e+01 8.50e+01]\n",
      " [1.70e+00 2.95e+02 6.00e+01 6.10e+01]\n",
      " [3.90e+00 1.20e+02 2.80e+01 4.30e+01]\n",
      " [1.00e+00 8.50e+01 2.00e+01 6.30e+01]\n",
      " [1.40e+00 8.50e+01 7.00e+01 3.50e+01]\n",
      " [1.90e+00 8.50e+01 1.14e+02 6.10e+01]\n",
      " [1.20e+00 7.50e+01 1.73e+02 5.40e+01]\n",
      " [4.20e+00 6.50e+01 1.20e+02 6.10e+01]\n",
      " [1.70e+00 1.09e+02 5.28e+02 3.50e+01]\n",
      " [9.00e-01 8.90e+01 1.52e+02 6.10e+01]\n",
      " [6.00e-01 1.20e+02 3.00e+01 6.10e+01]\n",
      " [7.60e+00 8.50e+01 2.42e+02 5.00e+01]\n",
      " [9.00e-01 1.26e+02 1.42e+02 6.10e+01]\n",
      " [8.00e-01 7.50e+01 2.00e+01 6.10e+01]\n",
      " [1.50e+00 8.10e+01 1.90e+01 4.80e+01]\n",
      " [1.20e+00 1.00e+02 1.90e+01 4.20e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "\n",
    "features = fit.transform(X)\n",
    "# Summarize selected features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discreatization\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(Y.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 8 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 9 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\haziq\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 18 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>STEROID</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>MALAISE</th>\n",
       "      <th>ANOREXIA</th>\n",
       "      <th>LIVER BIG</th>\n",
       "      <th>LIVER FIRM</th>\n",
       "      <th>SPLEEN PALPABLE</th>\n",
       "      <th>SPIDERS</th>\n",
       "      <th>ASCITES</th>\n",
       "      <th>VARICES</th>\n",
       "      <th>BILIRUBIN</th>\n",
       "      <th>ALK PHOSPHATE</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>ALBUMIN</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX  STEROID  ANTIVIRALS  FATIGUE  MALAISE  ANOREXIA  LIVER BIG  \\\n",
       "0    6.0  0.0      1.0         3.0      1.0      2.0       1.0        1.0   \n",
       "1    9.0  0.0      2.0         3.0      1.0      2.0       1.0        2.0   \n",
       "2    3.0  0.0      2.0         1.0      3.0      2.0       1.0        2.0   \n",
       "3    3.0  0.0      2.0         3.0      3.0      2.0       1.0        2.0   \n",
       "4    3.0  0.0      2.0         3.0      3.0      2.0       1.0        2.0   \n",
       "..   ...  ...      ...         ...      ...      ...       ...        ...   \n",
       "149  5.0  0.0      2.0         3.0      1.0      0.0       0.0        2.0   \n",
       "150  5.0  0.0      2.0         3.0      1.0      2.0       1.0        2.0   \n",
       "151  7.0  0.0      1.0         3.0      1.0      0.0       1.0        1.0   \n",
       "152  6.0  1.0      1.0         3.0      1.0      2.0       1.0        2.0   \n",
       "153  5.0  0.0      2.0         3.0      1.0      2.0       1.0        2.0   \n",
       "\n",
       "     LIVER FIRM  SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  BILIRUBIN  \\\n",
       "0           1.0              1.0      2.0      2.0      1.0        2.0   \n",
       "1           1.0              1.0      2.0      2.0      1.0        1.0   \n",
       "2           1.0              1.0      2.0      2.0      1.0        1.0   \n",
       "3           1.0              1.0      2.0      2.0      1.0        2.0   \n",
       "4           1.0              1.0      2.0      2.0      1.0        2.0   \n",
       "..          ...              ...      ...      ...      ...        ...   \n",
       "149         1.0              1.0      1.0      1.0      0.0        8.0   \n",
       "150         0.0              1.0      2.0      2.0      1.0        2.0   \n",
       "151         0.0              1.0      1.0      2.0      1.0        1.0   \n",
       "152         1.0              0.0      1.0      2.0      0.0        3.0   \n",
       "153         1.0              0.0      1.0      1.0      1.0        2.0   \n",
       "\n",
       "     ALK PHOSPHATE  SGOT  ALBUMIN  PROTIME  HISTOLOGY  \n",
       "0              4.0   1.0      3.0      6.0        1.0  \n",
       "1              2.0   0.0      5.0      6.0        1.0  \n",
       "2              0.0   1.0      5.0      7.0        1.0  \n",
       "3              2.0   5.0      5.0      6.0        1.0  \n",
       "4              2.0   0.0      5.0      7.0        1.0  \n",
       "..             ...   ...      ...      ...        ...  \n",
       "149            2.0   5.0      2.0      4.0        2.0  \n",
       "150            4.0   4.0      6.0      6.0        2.0  \n",
       "151            1.0   0.0      5.0      6.0        2.0  \n",
       "152            2.0   0.0      5.0      4.0        2.0  \n",
       "153            3.0   0.0      2.0      3.0        2.0  \n",
       "\n",
       "[154 rows x 19 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='kmeans')\n",
    "data = trans.fit_transform(X)\n",
    "data\n",
    "data_fordiscreat1=pd.DataFrame(data,columns=['AGE'\n",
    "      ,'SEX'\n",
    "      ,'STEROID'\n",
    "      ,'ANTIVIRALS'\n",
    "      ,'FATIGUE'\n",
    "      ,'MALAISE'\n",
    "     , 'ANOREXIA'\n",
    "     , 'LIVER BIG'\n",
    "     ,'LIVER FIRM'\n",
    "     ,'SPLEEN PALPABLE'\n",
    "     ,'SPIDERS'\n",
    "     ,'ASCITES'\n",
    "     ,'VARICES'\n",
    "     ,'BILIRUBIN'\n",
    "     ,'ALK PHOSPHATE'\n",
    "     ,'SGOT'\n",
    "     ,'ALBUMIN'\n",
    "     ,'PROTIME'\n",
    "     ,'HISTOLOGY'])\n",
    "data_fordiscreat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = KBinsDiscretizer(n_bins=10, encode='ordinal',strategy='uniform')\n",
    "X = X.astype('float64')\n",
    "X= trans.fit_transform(X)\n",
    "data_fordiscreat2=pd.DataFrame(data,columns=['AGE'\n",
    "      ,'SEX'\n",
    "      ,'STEROID'\n",
    "      ,'ANTIVIRALS'\n",
    "      ,'FATIGUE'\n",
    "      ,'MALAISE'\n",
    "     , 'ANOREXIA'\n",
    "     , 'LIVER BIG'\n",
    "     ,'LIVER FIRM'\n",
    "     ,'SPLEEN PALPABLE'\n",
    "     ,'SPIDERS'\n",
    "     ,'ASCITES'\n",
    "     ,'VARICES'\n",
    "     ,'BILIRUBIN'\n",
    "     ,'ALK PHOSPHATE'\n",
    "     ,'SGOT'\n",
    "     ,'ALBUMIN'\n",
    "     ,'PROTIME'\n",
    "     ,'HISTOLOGY'])\n",
    "\n",
    "X=data_fordiscreat2.values\n",
    "data_fordiscreat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Specs      Score\n",
      "13        BILIRUBIN  33.023740\n",
      "16          ALBUMIN  24.845949\n",
      "5           MALAISE  13.926163\n",
      "17          PROTIME  11.194506\n",
      "4           FATIGUE   7.591992\n",
      "0               AGE   5.877086\n",
      "1               SEX   3.934426\n",
      "14    ALK PHOSPHATE   3.467285\n",
      "10          SPIDERS   3.073308\n",
      "12          VARICES   2.354154\n",
      "11          ASCITES   2.044072\n",
      "9   SPLEEN PALPABLE   1.628900\n",
      "15             SGOT   1.363730\n",
      "6          ANOREXIA   0.559023\n",
      "3        ANTIVIRALS   0.523679\n",
      "2           STEROID   0.508337\n",
      "7         LIVER BIG   0.084453\n",
      "8        LIVER FIRM   0.018323\n"
     ]
    }
   ],
   "source": [
    "#selecting features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X = data_fordiscreat2.iloc[:,0:18]  #independent columns\n",
    "Y=df2.iloc[:, 0].values  #target column i.e price range#apply SelectKBest class to extract top 10 best features\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=8)\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(19,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selceting features\n",
    "X2=pd.DataFrame(data_fordiscreat2[[\"BILIRUBIN\"\n",
    "    ,\"ALBUMIN\"\n",
    "    ,\"MALAISE\"\n",
    "    ,\"PROTIME\",\n",
    "    \"FATIGUE\"\n",
    "    ,\"AGE\"\n",
    "    ,\"SEX\"\n",
    "    ,\"ALK PHOSPHATE\"\n",
    "    ,\"SPIDERS\"\n",
    "    ,\"VARICES\"\n",
    "    ,\"ASCITES\"\n",
    "   ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cd072b720d53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X=X2.values\n",
    "Y=df.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (107, 11) Training True Class labels dimensions (107,)\n",
      " Test Data Set Dimensions= (47, 11) Test True Class labels dimensions (107,)\n"
     ]
    }
   ],
   "source": [
    "# Spllit Data into train and test\n",
    "import Split as t \n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)   \n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes model accuracy(in %): 59.57446808510638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(Xtrain, Ytrain) \n",
    "  \n",
    "# making predictions on the testing set \n",
    "y_pred = gnb.predict(Xtest) \n",
    "  \n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "from sklearn import metrics \n",
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(Ytest, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(Xtrain,Ytrain)\n",
    "    \n",
    "    train_scores.append(knn.score(Xtrain,Ytrain))\n",
    "    test_scores.append(knn.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train score 100.0 % and k = [1]\n"
     ]
    }
   ],
   "source": [
    "max_train_score = max(train_scores)\n",
    "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test score 87.2340425531915 % and k = [5, 13]\n"
     ]
    }
   ],
   "source": [
    "max_test_score = max(test_scores)\n",
    "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851063829787234"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(6)\n",
    "\n",
    "knn.fit(Xtrain,Ytrain)\n",
    "knn.score(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  1   2  All\n",
       "True                 \n",
       "1          5   5   10\n",
       "2          2  35   37\n",
       "All        7  40   47"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#let us get the predictions using the classifier we had fit above\n",
    "y_pred = knn.predict(Xtest)\n",
    "confusion_matrix(Ytest,y_pred)\n",
    "pd.crosstab(Ytest, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 12.5, 'Predicted label')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "y_pred = knn.predict(Xtest)\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(Ytest, y_pred)\n",
    "p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=26, 1=97, Test: 0=6, 1=25\n",
      ">Train: 0=26, 1=97, Test: 0=6, 1=25\n",
      ">Train: 0=25, 1=98, Test: 0=7, 1=24\n",
      ">Train: 0=25, 1=98, Test: 0=7, 1=24\n",
      ">Train: 0=26, 1=98, Test: 0=6, 1=24\n"
     ]
    }
   ],
   "source": [
    "# Kfold cross-validation\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(X, Y):\n",
    "    \n",
    "    train_X, test_X = X[train_ix], X[test_ix]\n",
    "    train_y, test_y = y[train_ix], y[test_ix]\n",
    "    \n",
    "    train_0, train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "    test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1])\n",
    "    print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
